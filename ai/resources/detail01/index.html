<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- SEO -->
    <link rel="icon" href="/resource/images/ai/KT_16.ico" />
    <title>KT가 자체 개발한 AI 모델 믿:음2.0을 출시하고 오픈소스로 공개합니다.</title>
    <meta name="description" content="한국 AI 생태계와 개발자 커뮤니티를 지원하기 위해, 국내 최초 11B 규모의 상업적 활용 가능한 모델을 오픈소스로 공개" />
    <meta name="keywords" content="Language, Model, 믿:음, 믿:음2.0, 믿:음2.0 base, 믿:음2.0 mini" />

    <!-- SNS 공유용 -->
    <meta property="og:title" content="KT가 자체 개발한 AI 모델 믿:음2.0을 출시하고 오픈소스로 공개합니다." />
    <meta property="og:description" content="한국 AI 생태계와 개발자 커뮤니티를 지원하기 위해, 국내 최초 11B 규모의 상업적 활용 가능한 모델을 오픈소스로 공개" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="KT AI" />

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/ai/common/common.css" />
    <!-- Reset CSS -->
    <link rel="stylesheet" href="/css/ai/common/reset.css" />
    <!-- Style CSS -->
    <link rel="stylesheet" href="/css/ai/solution_cy.css" />
    <!-- AOS CSS -->
    <link rel="stylesheet" href="/css/ai/common/aos.css" />
</head>

<body>
    <!-- Header -->
    <header id="main-header" class="header">
        <div class="header-inner"></div>
    </header>

    <div class="sub-content techDetailPage">
        <div class="sub-inner">
            <div class="tech-detail-header">
                <span class="tech-detail-category">What's New</span>
                <h1 class="tech-detail-title">
                    KT가 자체 개발한 AI 모델 믿:음2.0을 <br>
                    출시하고 오픈소스로 공개합니다.
                </h1>
                <div class="card-tags">
                    <span>Language</span>
                    <span>Model</span>
                    <span>믿:음</span>
                    <span>믿:음2.0</span>
                    <span>믿:음2.0 base</span>
                    <span>믿:음2.0 mini</span>
                </div>
                <time class="tech-detail-date" datetime="2025-05-16">2025.05.16</time>
            </div>

            <!-- 게시글 본문 영역 (관리자 에디터/HTML 입력용) -->
            <article class="tech-detail-article" id="tech-detail-article">
                <!--
                      ※ 관리자 페이지에서 등록한 게시글의 본문(HTML)이 이 영역에 삽입됩니다.
                      예시:
                      <h2>본문 제목</h2>
                      <p>본문 내용...</p>
                      <img src="..." alt="..." />
                      ...
                    -->

                <!-- 작업요청 -->
                <section class="post-custom">
                    <p>KT의 AI 모델 ‘믿:음ʼ은 국내 AI 기술 주권 확보를 위한 KT의 언어모델(LLM)로, 2023년 1.0 버전 Standard, Premium 2종을 출시한 이래로,
                        KT AICC, 지니TV, AI 통화비서, 100번 콜센터 등 KT 서비스에 다방면으로 활용되어 왔습니다.</p>
                    <p>2025년 7월, 한국적 AI라는 이름에 걸맞게 한층 강력해진 믿:음 2.0을 선보입니다. 한국적 AI는 한국의 정신(Value), 방식(Style),
                        지식(Knowledge)을 깊이 이해하고, 한국의 역사, 사회, 국가관을 알며, 국내 제도와 규제에 부합하는 안전한 AI 모델입니다. 이를 위해 다양한 Data
                        Alliance를 통해 고품질의 인증된 한국어 데이터를 확보하였고, 종합적인 한국 이해 능력 측정을 위해 자체적으로 한국적 AI 6대 평가지표와 벤치마크 4종을 구축했으며,
                        윤리적 사용성 개선을 위해 RAI(Responsible AI) 평가를 종합적으로 수행하였습니다. 또한 한국어 고품질 데이터의 이용으로 타사 LLM 대비 압도적으로 적은
                        Token 수의 학습으로 고성능을 낼 수 있음을 입증하였고, 한국어에 최적화된 고유의 Tokenizer를 사용하여 압축률을 높이고 추론 효율성을 확보하였습니다.</p>
                    <p>믿:음 2.0은 mini, base, pro(출시 예정)로 모델 라인업을 구성하였습니다. 이 중 11B 규모의 base 모델과 2.3B 규모의 mini 모델을 오픈소스로
                        공개합니다. 믿:음 2.0 모델 공개를 통해 한국의 다양한 산업과 공공 분야에서 AX를 통한 혁신이 이루어질 수 있기를 바라고, 한국 AI 개발자 커뮤니티에도 실질적인
                        도움이 되기를 기대합니다.</p>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post01_re.png" alt="">
                    </div>
                </section>


                <section class="post-custom">
                    <h3>문서기반 QA 성능 강화</h3>
                    <p>믿:음 2.0에는 지식증류(Distillation)를 적용하여 성능 저하를 최소화하면서도 모델 사이즈를 줄인 경량화 모델 mini가 새로이 추가되었습니다. 또한
                        병렬화(Parallelism) 구현으로 학습 속도를 개선하였고, 성능 측면에선 문서이해/QA 등 시장 요구 능력을 집중 강화하였으며 긴 길이의 문서 입력을 위한
                        Context 길이를 대폭 증가시켰습니다(mini/base는 8K에서 32K로 증가). 윤리적 사용성을 한층 개선하기 위해, 지도학습(Supervised
                        Fine-tuning)과 성능 평가에 Safety 요소를 세밀하게 적용하였습니다.</p>
                    <p>사용성 개선을 위해 고객 요구 기능들을 업데이트하였는데, 특히 업무효율화를 위해 문서 기반의 QA 성능을 대폭 개선하였습니다.</p>
                </section>

                <section class="post-custom">
                    <h3> Architecture & Method</h3>
                    <p>믿:음 2.0은 Transformer 구조를 활용한 decoder-only 모델입니다. 제한된 컴퓨팅 자원 하에서 성능을 극대화하기 위하여 8B 규모의 core 모델을
                        바탕으로 Depth-up-Scaling(DuS) 하여 11.5B 규모의 base 모델을 생성했습니다. mini는 base 모델은 두 단계에 걸쳐 pruning과
                        distillation 하여 생성한 모델이고, pro(출시예정)는 효율적 학습과 추론을 위해 MoE(Mixture of Expert) 구조를 적용한 모델입니다.</p>
                    <p>mini와 base의 Post-training은 SFT(Supervised fine-tuning) 이후 sDPO(Stepwise Direct Preference
                        Optimization)4를 진행하였습니다.</p>
                </section>

                <section class="post-custom">
                    <h3>한국어에 최적화된 고유의 Tokenizer 적용</h3>
                    <p>Pre-training 단계에서 사용하는 Tokenizer는 LLM 성능은 물론 연산 효율에도 영향을 미치는 핵심 요소로서, 믿:음 2.0에는 한국어와 영어에 효과적인 KT
                        고유의 bi-lingual bbpe(byte-level bpe) Tokenizer를 적용했습니다. KT의 Tokenizer는 한국어에 대해 GPT-4 대비 최대 약
                        110%, 국내 타사 모델 대비 최대 약 23%까지 향상된 압축 성능을 보여줍니다.</p>

                    <p>여러 단어와 형태소의 결합에 따라 의미가 결정되는 한국어의 특성을 고려하여, 한국어 Tokenizer 개발 시에 형태소 분석으로 pre tokenization을 빈번하게
                        진행하게 됩니다. 이 때 전체 데이터에 대해 형태소 분석을 진행할 경우, 압축률 저하 문제가 발생합니다. 이를 해결하기 위해 Tokenizer 학습 시 '조사ʼ에만 pre
                        tokenization을 적용하였고, 이를 통해 한국어의 특성을 잘 반영하면서 압축률도 향상된 한국어 Tokenizer를 개발할 수 있었습니다.</p>

                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post02_re.png" alt="">
                    </div>
                </section>

                <section class="post-custom">
                    <h3>Performance<br>
                        1. 한국 특화능력 전 분야에서 최고 수준 달성
                    </h3>
                    <p>
                        매월

                        모델

                        성능

                        평가를

                        위해

                        벤치마크
                        , LLM Judge,
                        및

                        휴먼

                        평가를

                        진행하고

                        있으며
                        ,
                        특히

                        벤치마크

                        평가는

                        글로벌

                        벤치마크

                        뿐만

                        아
                        니라
                        KT
                        가

                        한국적
                        AI
                        지표를

                        넣어

                        개발한
                        K
                        벤치마크

                        평가도

                        실시하고

                        있습니다
                        .
                    </p>

                    <p>믿
                        :
                        음
                        2.0 base
                        모델은
                        <b>한국 특화 능력이 내/외부(국내/국외) 모델 대비 모든 영역에서 우위</b>를

                        기록하였으며
                        ,
                        특히
                        <b>심화 지식을 요하는
                            어려운 문항에서 강점</b>을

                        보였습니다
                        . (Hard K-Pragmatics, Ko-ComprehensiveGen-, K-Referential
                        모두
                        1
                        위
                        )
                    </p>

                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post03_re.png" alt="">
                        <h5>[한국 특화 능력]
                        </h5>
                    </div>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post04_re.png" alt="">
                        <h5> [한국 특화 능력-Hard (K-Pragmatic/ComprehesiveGen/Referential]
                        </h5>
                    </div>

                    <h3> 2.
                        영어
                        공통
                        능력은
                        글로벌
                        수준
                        보유</h3>
                    <p>영어

                        공통

                        능력의

                        경우
                        ,
                        추론
                        /
                        수학

                        영역을

                        제외하고는

                        글로벌

                        모델들과

                        유사한

                        수준을

                        보였으며
                        ,
                        특히
                        전문지식(Bio/Med) 영역
                        에서
                        우위가

                        있습니다
                        .</p>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post05_re.png" alt="">
                        <h5> [한국 특화 능력-Hard (K-Pragmatic/ComprehesiveGen/Referential]
                        </h5>
                    </div>
                </section>

                <section class="post-custom">

                </section>

                <!-- //작업요청 -->

                <!-- <img class="pc-only" src="/resource/images/ai/resources/techDetail_test.png" alt="" />
                <img class="mobile-show" src="/resource/images/ai/resources/techDetail_test_mobile.png" alt="" /> -->
                <div class="tech-detail-article-list">
                    <h3>Technical Resources</h3>
                    <ul>
                        <li><a href="#">Mi:dm 2.0 Technical Report 바로가기</a></li>
                        <li class="has-icon">
                            <a href="#">Mi:dm 2.0 Model Download 바로가기 </a>
                            <div class="detail-inform">
                                <em class="pc-only">ㅣ </em><span>일정 조건을 만족하면 상업적 목적으로도 자유롭게 이용 가능합니다.</span>
                            </div>
                        </li>
                        <li><a href="#">K on Studio(AI개발도구) 바로가기 </a></li>
                        <li class="mo-has-border has-icon">
                            <div class="detail-inform">
                                <span>향후 Microsoft Azure를 통해 Mi:dm API를 제공할 예정입니다.</span>
                            </div>
                        </li>
                    </ul>
                </div>
                <div class="tech-detail-article-list gap-40">
                    <h3>Technical Resources</h3>
                    <ul class="gap-12">
                        <li>
                            <p>AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</p>
                        </li>
                        <li>
                            <p>Qingyun Wu, Gagan Bansal, Jieyu Zhang</p>
                        </li>
                        <li>
                            <p>August 2024, Best Paper, LLM Agents Workshop ICLR 2024</p>
                        </li>
                    </ul>
                    <ul class="pdf-ul">
                        <li><a href="#">PDF 바로보기</a></li>
                        <li><a href="#">PDF 다운로드</a></li>
                    </ul>
                </div>
                <a href="#" class="KonModel-link">K Models 체험하기</a>
            </article>

            <div class="tech-detail-bottom">
                <a href="/ai/resources/">
                    <button type="button" class="basic-bk-btn docs-back">돌아가기</button>
                </a>
                <div class="tech-banner-sec"></div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer class="footer"></footer>

    <!-- Script -->
    <script src="/js/ai/solution.js"></script>
    <script src="/js/ai/common/common.js"></script>
    <script>
        includeCommonLayout({ skipKtModel: true });
    </script>
</body>

</html>