<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- SEO -->
    <link rel="icon" href="/resource/images/ai/KT_16.ico" />
    <title>KT가 자체 개발한 AI 모델 믿:음2.0을 출시하고 오픈소스로 공개합니다.</title>
    <meta name="description" content="한국 AI 생태계와 개발자 커뮤니티를 지원하기 위해, 국내 최초 11B 규모의 상업적 활용 가능한 모델을 오픈소스로 공개" />
    <meta name="keywords" content="Language, Model, 믿:음, 믿:음2.0, 믿:음2.0 base, 믿:음2.0 mini" />

    <!-- SNS 공유용 -->
    <meta property="og:title" content="KT가 자체 개발한 AI 모델 믿:음2.0을 출시하고 오픈소스로 공개합니다." />
    <meta property="og:description" content="한국 AI 생태계와 개발자 커뮤니티를 지원하기 위해, 국내 최초 11B 규모의 상업적 활용 가능한 모델을 오픈소스로 공개" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="KT AI" />

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/ai/common/common.css" />
    <!-- Reset CSS -->
    <link rel="stylesheet" href="/css/ai/common/reset.css" />
    <!-- Style CSS -->
    <link rel="stylesheet" href="/css/ai/solution_cy.css" />
    <!-- AOS CSS -->
    <link rel="stylesheet" href="/css/ai/common/aos.css" />
</head>

<body>
    <!-- Header -->
    <header id="main-header" class="header">
        <div class="header-inner"></div>
    </header>

    <div class="sub-content techDetailPage">
        <div class="sub-inner">
            <div class="tech-detail-header">
                <span class="tech-detail-category">What's New</span>
                <h1 class="tech-detail-title">
                    KT가 자체 개발한 AI 모델 믿:음2.0을 <br>
                    출시하고 오픈소스로 공개합니다.
                </h1>
                <div class="card-tags">
                    <span>Language</span>
                    <span>Model</span>
                    <span>믿:음</span>
                    <span>믿:음2.0</span>
                    <span>믿:음2.0 base</span>
                    <span>믿:음2.0 mini</span>
                </div>
                <time class="tech-detail-date" datetime="2025-05-16">2025.05.16</time>
            </div>

            <!-- 게시글 본문 영역 (관리자 에디터/HTML 입력용) -->
            <article class="tech-detail-article" id="tech-detail-article">
                <!--
                      ※ 관리자 페이지에서 등록한 게시글의 본문(HTML)이 이 영역에 삽입됩니다.
                      예시:
                      <h2>본문 제목</h2>
                      <p>본문 내용...</p>
                      <img src="..." alt="..." />
                      ...
                    -->

                <!-- 작업요청 -->
                <section class="post-custom">
                    <p>KT의 AI 모델 ‘믿:음ʼ은 국내 AI 기술 주권 확보를 위한 KT의 언어모델(LLM)로, 2023년 1.0 버전 Standard, Premium 2종을 출시한 이래로,
                        KT AICC, 지니TV, AI 통화비서, 100번 콜센터 등 KT 서비스에 다방면으로 활용되어 왔습니다.</p>
                    <p>2025년 7월, 한국적 AI라는 이름에 걸맞게 한층 강력해진 믿:음 2.0을 선보입니다. 한국적 AI는 한국의 정신(Value), 방식(Style),
                        지식(Knowledge)을 깊이 이해하고, 한국의 역사, 사회, 국가관을 알며, 국내 제도와 규제에 부합하는 안전한 AI 모델입니다. 이를 위해 다양한 Data
                        Alliance를 통해 고품질의 인증된 한국어 데이터를 확보하였고, 종합적인 한국 이해 능력 측정을 위해 자체적으로 한국적 AI 6대 평가지표와 벤치마크 4종을 구축했으며,
                        윤리적 사용성 개선을 위해 RAI(Responsible AI) 평가를 종합적으로 수행하였습니다. 또한 한국어 고품질 데이터의 이용으로 타사 LLM 대비 압도적으로 적은
                        Token 수의 학습으로 고성능을 낼 수 있음을 입증하였고, 한국어에 최적화된 고유의 Tokenizer를 사용하여 압축률을 높이고 추론 효율성을 확보하였습니다.</p>
                    <p>믿:음 2.0은 mini, base, pro(출시 예정)로 모델 라인업을 구성하였습니다. 이 중 11B 규모의 base 모델과 2.3B 규모의 mini 모델을 오픈소스로
                        공개합니다. 믿:음 2.0 모델 공개를 통해 한국의 다양한 산업과 공공 분야에서 AX를 통한 혁신이 이루어질 수 있기를 바라고, 한국 AI 개발자 커뮤니티에도 실질적인
                        도움이 되기를 기대합니다.</p>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post01.png" alt="">
                    </div>
                </section>


                <section class="post-custom">
                    <h3>문서기반 QA 성능 강화</h3>
                    <p>믿:음 2.0에는 지식증류(Distillation)를 적용하여 성능 저하를 최소화하면서도 모델 사이즈를 줄인 경량화 모델 mini가 새로이 추가되었습니다. 또한
                        병렬화(Parallelism) 구현으로 학습 속도를 개선하였고, 성능 측면에선 문서이해/QA 등 시장 요구 능력을 집중 강화하였으며 긴 길이의 문서 입력을 위한
                        Context 길이를 대폭 증가시켰습니다(mini/base는 8K에서 32K로 증가). 윤리적 사용성을 한층 개선하기 위해, 지도학습(Supervised
                        Fine-tuning)과 성능 평가에 Safety 요소를 세밀하게 적용하였습니다.</p>
                    <p>사용성 개선을 위해 고객 요구 기능들을 업데이트하였는데, 특히 업무효율화를 위해 문서 기반의 QA 성능을 대폭 개선하였습니다.</p>
                </section>

                <section class="post-custom">
                    <h3> Architecture & Method</h3>
                    <p>믿:음 2.0은 Transformer 구조를 활용한 decoder-only 모델입니다. 제한된 컴퓨팅 자원 하에서 성능을 극대화하기 위하여 8B 규모의 core 모델을
                        바탕으로 Depth-up-Scaling(DuS) 하여 11.5B 규모의 base 모델을 생성했습니다. mini는 base 모델은 두 단계에 걸쳐 pruning과
                        distillation 하여 생성한 모델이고, pro(출시예정)는 효율적 학습과 추론을 위해 MoE(Mixture of Expert) 구조를 적용한 모델입니다.</p>
                    <p>mini와 base의 Post-training은 SFT(Supervised fine-tuning) 이후 sDPO(Stepwise Direct Preference
                        Optimization)4를 진행하였습니다.</p>
                </section>

                <section class="post-custom">
                    <h3>한국어에 최적화된 고유의 Tokenizer 적용</h3>
                    <p>Pre-training 단계에서 사용하는 Tokenizer는 LLM 성능은 물론 연산 효율에도 영향을 미치는 핵심 요소로서, 믿:음 2.0에는 한국어와 영어에 효과적인 KT
                        고유의 bi-lingual bbpe(byte-level bpe) Tokenizer를 적용했습니다. KT의 Tokenizer는 한국어에 대해 GPT-4 대비 최대 약
                        110%, 국내 타사 모델 대비 최대 약 23%까지 향상된 압축 성능을 보여줍니다.</p>

                    <p>여러 단어와 형태소의 결합에 따라 의미가 결정되는 한국어의 특성을 고려하여, 한국어 Tokenizer 개발 시에 형태소 분석으로 pre tokenization을 빈번하게
                        진행하게 됩니다. 이 때 전체 데이터에 대해 형태소 분석을 진행할 경우, 압축률 저하 문제가 발생합니다. 이를 해결하기 위해 Tokenizer 학습 시 '조사ʼ에만 pre
                        tokenization을 적용하였고, 이를 통해 한국어의 특성을 잘 반영하면서 압축률도 향상된 한국어 Tokenizer를 개발할 수 있었습니다.</p>

                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post03.png" alt="">
                    </div>
                </section>

                <section class="post-custom">
                    <h3>Performance<br>
                        1. 한국 특화능력 전 분야에서 최고 수준 달성
                    </h3>
                    <p>
                        매월

                        모델

                        성능

                        평가를

                        위해

                        벤치마크
                        , LLM Judge,
                        및

                        휴먼

                        평가를

                        진행하고

                        있으며
                        ,
                        특히

                        벤치마크

                        평가는

                        글로벌

                        벤치마크

                        뿐만

                        아
                        니라
                        KT
                        가

                        한국적
                        AI
                        지표를

                        넣어

                        개발한
                        K
                        벤치마크

                        평가도

                        실시하고

                        있습니다
                        .
                    </p>

                    <p>믿
                        :
                        음
                        2.0 base
                        모델은
                        <b>한국 특화 능력이 내/외부(국내/국외) 모델 대비 모든 영역에서 우위</b>를

                        기록하였으며
                        ,
                        특히
                        <b>심화 지식을 요하는
                            어려운 문항에서 강점</b>을

                        보였습니다
                        . (Hard K-Pragmatics, Ko-ComprehensiveGen-, K-Referential
                        모두
                        1
                        위
                        )
                    </p>

                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post04.png" alt="">
                        <h5>[한국 특화 능력]
                        </h5>
                    </div>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post05.png" alt="">
                        <h5> [한국 특화 능력-Hard (K-Pragmatic/ComprehesiveGen/Referential]
                        </h5>
                    </div>

                    <h3> 2.
                        영어
                        공통
                        능력은
                        글로벌
                        수준
                        보유</h3>
                    <p>영어

                        공통

                        능력의

                        경우
                        ,
                        추론
                        /
                        수학

                        영역을

                        제외하고는

                        글로벌

                        모델들과

                        유사한

                        수준을

                        보였으며
                        ,
                        특히
                        전문지식(Bio/Med) 영역
                        에서
                        우위가

                        있습니다
                        .</p>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post06.png" alt="">
                        <h5> [한국 특화 능력-Hard (K-Pragmatic/ComprehesiveGen/Referential]
                        </h5>
                    </div>
                </section>

                <section class="post-custom">
                    <h3>[RAI 영향평가]</h3>
                    <p>AI 의 전 생애주기에 걸쳐 AI 가 인간의 삶에 미치는 영향을 평가하는 지표로, KT RAI Center 에서는 5개 RAI 원칙을 기준으로(책임
                        성, 지속가능성, 투명성, 신뢰성, 포용성) 국내 AI 기본법 등 규제 방향에 맞추어 평가 기준인 RAI Requirements를 정립하였습니다.
                        RAI 영향평가는 약 40여 개 항목으로 구성되어 있으며, 의도된 사용(intended use case)과 비의도된 사용(unintended use case)
                        사례를 분석합니다. 평가에는 AI 기본법에 의거한 고영향 인공지능 여부 판단 및 그에 따른 세부 검토와 더불어 AI가 사회에 미치는
                        긍정적•부정적 영향을 검토하는 과정이 포함됩니다.</p>

                    <p>믿:음 Pro, Base, Mini 모델 영향평가는 2025년 2월부터 6월까지 진행되었습니다. 믿:음은 KT가 데이터 수집부터 배포까지 자체적
                        으로 개발한 모델이며, 오픈 소스 형태로 배포된다는 특성을 고려하여 데이터 투명성과 이해관계자 커뮤니케이션 등 투명성, 데이터
                        신뢰성 및 AI 시스템의 품질 등 신뢰성 관점에서 면밀히 검토하였습니다.</p>
                </section>


                <section class="post-custom">
                    <h3>[RAI 안전평가]</h3>
                    <p>AI 가 생성한 답변 및 결과물의 안전성을 평가하는 지표로서, RAI Center 에서는 정성평가 및 벤치마크 평가를 통해 응답의 유해성과
                        신뢰성을 사전에 점검하고, 레드티밍을 통해 강건성을 평가합니다. 또한 전문가 그룹을 통한 안전성 심의를 통해 모델 및 서비스의 안
                        전성을 최종 평가하게 됩니다. 2025년 2월 RAI 영향평가서에 따르면, 믿:음 base 모델은 공정성을 평가하는 지표인 KoBBQ한국
                        어), BBQ에서 국내외 모델 대비 각각 1, 2위 결과를 받았습니다.
                    </p>
                    <div class="img">
                        <img src="/resource/images/ai/resources/detail01/post06_re.png" alt="">
                        <h5>레드티밍 평가 Set: 공격 성공률(ASR) : (00%) (1위 (00%)</h5>
                    </div>
                </section>

                <div class="post-custom">
                    <h3>마무리글</h3>
                    <p>향후에는 MoEMixture of Experts) 구조와 같은 대규모 모델 아키텍처 확장 및 이에 대한 학습 효율성 연구를 지속할 계획입니다. 또
                        한 한국어와 영어 외에도 다양한 국가의 언어를 포함한 다국어 학습을 확대하고, 수학·코드·추론 영역에서의 모델 성능 강화를 위한
                        개발에도 힘쓸 것 입니다.
                    </p>
                    <p>KT는 믿:음 모델 공개를 통해, AI를 활용한 기업의 기술 혁신과 개발자 생태계의 성장에 실질적인 기여를 하고자 합니다. 믿:음 모델
                        이 다양한 산업 및 연구 현장에서 활용되어, 더 나은 AI 경험을 가능하게 하는 기반이 되기를 기대합니다.
                    </p>
                </div>

                <!-- //작업요청 -->

                <!-- <img class="pc-only" src="/resource/images/ai/resources/techDetail_test.png" alt="" />
                <img class="mobile-show" src="/resource/images/ai/resources/techDetail_test_mobile.png" alt="" /> -->
                <div class="tech-detail-article-list">
                    <h3>Technical Resources</h3>
                    <ul>
                        <li><a href="#">믿:음2.0 base Model Card 바로가기</a></li>
                        <li class="has-icon">
                            <a href="#">믿:음2.0 mini Model Card 바로가기</a>
                        </li>
                        <li><a href="#">Technical Report (공개예정)</a></li>

                        <li><a href="#">믿:음2.0 Model Download 바로가기</a>
                            <div class="detail-inform">
                                <em class="pc-only">ㅣ </em><span>일정 조건을 만족하면 상업적 목적으로도 자유롭게 이용 가능합니다.</span>
                            </div>
                        </li>
                        <li class="mo-has-border has-icon">
                            <div class="detail-inform">
                                <span>향후 Microsoft Azure를 통해 믿:음2.0 API를 제공할 예정입니다.
                                </span>
                            </div>
                        </li>
                    </ul>
                </div>
            </article>
            <div class="tech-detail-article-list">
                <h3>Publications</h3>
                <ul class="vertical">
                    <li><a href="https://arxiv.org/abs/2412.01129" target="_blank">“RILQ: Rank-Insensitive LoRA-based
                            Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy”</a>, <br>
                        AAAI
                        2025
                        Geonho Lee, Janghwan Lee, Sukjin Hong, Minsoo Kim, Euijai Ahn, Du-Seong Chang, Jungwook Choi
                    </li>
                </ul>
            </div>
            <div class="tech-detail-bottom">
                <a href="/ai/resources/">
                    <button type="button" class="basic-bk-btn docs-back">돌아가기</button>
                </a>
                <div class="tech-banner-sec"></div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer class="footer"></footer>

    <!-- Script -->
    <script src="/js/ai/solution.js"></script>
    <script src="/js/ai/common/common.js"></script>
    <script>
        includeCommonLayout({ skipKtModel: true });
    </script>
</body>

</html>